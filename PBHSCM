# Author: Ce Shi
# Last updated: 2/23/2025
# Description:
The code was created to implement the ML models to predict peripheral blood hematopoietic stem cell mobilization in healthy volunteers.

##### Collinear variables or irrelevant features####
library(ggplot2)
col_types <- sapply(result_value, class)
non_numeric_cols <- col_types != "numeric"
result_value_non_numeric <- result_value[, non_numeric_cols]
print(result_value_non_numeric)
result_value$性别.男1.女2.=as.numeric(result_value$性别.男1.女2.)
result_value$MCHC=as.numeric(result_value$MCHC)
result_value$血小板 =as.numeric(result_value$血小板 )
result_value$尿酸 =as.numeric(result_value$尿酸 )
result_value$肌酐=as.numeric(result_value$肌酐)
result_value$age=as.numeric(result_value$age)
result_value$times =as.numeric(result_value$times )
result_value$收集年份=as.numeric(result_value$收集年份)
colnames(result_value) <- c("Gender", "Neutrophil", "Hemoglobin","RBC","HCT","MCV","MCHC","Platelets","Albumin","Globulin","Triglycerides","TC","LDL","Uric acid","Creatinine","BUN","GFR","BG","Weight","Height","BMI","WBC","Monocyte","Lymphocyte","Day4 CD34+ cell","Total mobilizer dose","Mobilizer dose per body weight","Age","Dosage frequency per day","Year of data collection")
cor_matrix <- cor(result_value, use = "complete.obs")  # 使用complete.obs来处理缺失值
test_result <- cor.test(result_value$`Day4 CD34+ cell`, result_value$BUN, method = "pearson")
print(cor_matrix)
write.csv(cor_matrix, "cor_matrix.csv", row.names = TRUE)
threshold <- 0.7
high_cor_var <- findCorrelation(cor_matrix, cutoff = threshold, verbose = TRUE)
ggplot(data = as.data.frame(as.table(cor_matrix)), aes(Var1, Var2, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1),
        axis.text.y = element_text(size = 12)) +
  coord_fixed() +
  ggtitle("Correlation Matrix Heatmap")
result_value_clean <- result_value[, !names(result_value) %in% names(result_value)[high_cor_var]]



#### Linear Regression####
library(caret)
set.seed()
index <- sample(nrow(result), round(nrow(result) * 0.7))
train_data <- result[index, ]
test_data <- result[-index, ]
train_control <- trainControl(method = "cv", number = 10,savePredictions = "final")
formula <- D4.CD34 ~ 性别.男1.女2. + 尿酸 + 基线白细胞.X109.l. + sum_mobilizer + 血小板 +
  血红蛋白.g.l. + 体重.Kg. + 升高.米. + 中性粒细胞数 + 单核细胞数 + 红细胞.x10.12.l. +
  肌酐 + MCHC + HCT + 淋巴细胞数目 + 甘油三酯 + LDL + 白蛋白 +
  times + age + mobilizer_bw + 收集年份
model_cv <- train(formula, data = train_data, method = "lm", trControl = train_control)
print(model_cv)
predictions_cv <- predict(model_cv, newdata = test_data)
predictions_bin_cv <- ifelse(predictions_cv > 500, 1, 0)
library(pROC)
roc_curve_cv <- roc(test_data$D4_CD34_binary, predictions_bin_cv)
print(roc_curve_cv$auc)
plot(roc_curve_cv, main = "ROC Curve", print.auc = TRUE)
plot(roc_curve_cv,  col="blue", main=" ROC Curves") 


#### Decision Tree####
library(rpart)     
library(rpart.plot) 
library(caret)      
result_factor<- data
result_factor$D4_CD34_binary <- as.factor(ifelse(result_factor$D4_CD34_binary == 1, "pos", "neg"))
levels(result_factor$D4_CD34_binary) <- c("neg", "pos") 
train_control <- trainControl(
  method = "cv",      
  number = 10,       
  search = "grid",    
  classProbs = TRUE,  
  summaryFunction = twoClassSummary,  
  savePredictions = "final" 
)
set.seed()
model3 <- train(
  D4_CD34_binary ~ 性别.男1.女2. + 尿酸 + 基线白细胞.X109.l. + sum_mobilizer + 血小板 +
    血红蛋白.g.l. + 体重.Kg. + 升高.米. + 中性粒细胞数 + 单核细胞数 + 红细胞.x10.12.l. +
    肌酐 + MCHC + HCT + 淋巴细胞数目 + 甘油三酯 + LDL + 白蛋白 +
    times + age + mobilizer_bw + 收集年份,
  data = result_factor,
  method = "rpart",
  trControl = train_control,
  tuneLength = 10,   
  metric = "ROC"   
)
print(model3)
rpart.plot(model3$finalModel, type = 3, fallen.leaves = TRUE)
importance <- varImp(model3, scale = FALSE)
print(importance)

predictions <- model3$pred
best_predictions <- subset(model3$pred, cp == model3$bestTune$cp)
roc_curve <- roc(best_predictions$obs, best_predictions$pos)
plot(roc_curve, main = "ROC Curve for Optimal Model", col = "blue", print.auc = TRUE)
lines(roc_curve, col="red", lty=1)
best_threshold <- coords(roc_curve, "best", ret = "threshold")
fold_accuracies <- numeric(10)
for (fold in unique(best_predictions$Resample)) {
  fold_data <- subset(best_predictions, Resample == fold)
  predicted_classes <- ifelse(fold_data$pos > 0.5, "pos", "neg")
  predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
  accuracy <- sum(predicted_classes == fold_data$obs) / nrow(fold_data)
  fold_accuracies[as.numeric(gsub("Fold", "", fold))] <- accuracy
  
  cat("Fold", fold, "Accuracy:", accuracy, "\n")
}
mean_accuracy <- mean(fold_accuracies)



#### Random Forest####
library(randomForest)  
result_factor$D4_CD34_binary=as.numeric(result_factor$D4.CD34>500)
result_factor$D4_CD34_binary <- as.factor(ifelse(result_factor$D4_CD34_binary == 1, "pos", "neg"))
levels(result_factor$D4_CD34_binary) <- c("neg", "pos") 
set.seed()
train_control <- trainControl(method = "cv",  
                              number = 10,    
                              classProbs = TRUE,  
                              summaryFunction = twoClassSummary,  
                              verboseIter = FALSE,
                              savePredictions = "final" )  
rf_model <- train(D4_CD34_binary ~ 性别.男1.女2.+ 尿酸+基线白细胞.X109.l.+sum_mobilizer+血小板
                  +血红蛋白.g.l.+体重.Kg.+升高.米.+中性粒细胞数+单核细胞数+红细胞.x10.12.l.
                  +肌酐+MCHC+HCT+淋巴细胞数目+甘油三酯+LDL+白蛋白
                  +times+age+mobilizer_bw,  
                  data = result_factor,
                  method = "rf",
                  trControl = train_control,
                  tuneLength = 3,
                  importance = TRUE,
                  ntree = 323)
print(rf_model)
best_predictions <- subset(rf_model $pred, mtry == rf_model $bestTune$mtry)
roc_curve <- roc(best_predictions$obs, best_predictions$pos)
plot(roc_curve, main = "ROC Curve for Optimal Model", col = "blue", print.auc = TRUE)
lines(roc_curve, col="green", lty=2)
fold_accuracies <- numeric(10)
for (fold in unique(best_predictions$Resample)) {
  fold_data <- subset(best_predictions, Resample == fold)
  predicted_classes <- ifelse(fold_data$pos > 0.5, "pos", "neg")
  predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
  accuracy <- sum(predicted_classes == fold_data$obs) / nrow(fold_data)
  fold_accuracies[as.numeric(gsub("Fold", "", fold))] <- accuracy
  cat("Fold", fold, "Accuracy:", accuracy, "\n")
}
mean_accuracy <- mean(fold_accuracies)
predicted_classes <- ifelse(best_predictions$pos > 0.5, "pos", "neg")
predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
confusion_matrix <- confusionMatrix(predicted_classes, best_predictions$obs)
print(confusion_matrix)




#### Support Vector Machine####
library(caret)
library(e1071)
set.seed(100)
normalization_data$D4_CD34_binary <- as.factor(normalization_data$D4_CD34_binary)
levels(normalization_data$D4_CD34_binary) <- c("Yes", "No")
train_control <- trainControl(
  method = "cv",
  number = 10,
  search = "grid", 
  classProbs = TRUE,
  summaryFunction = twoClassSummary, 
  allowParallel = TRUE , 
  savePredictions = "final")
tuneGrid <- expand.grid(sigma = seq(0.01, 1, by = 0.05), C = seq(1, 100, by = 10))
model5 <- train(
  D4_CD34_binary ~性别.男1.女2.+尿酸+基线白细胞.X109.l.+sum_mobilizer+血小板
  +血红蛋白.g.l.+体重.Kg.+升高.米.+中性粒细胞数+单核细胞数+红细胞.x10.12.l.
  +肌酐+MCHC+HCT+淋巴细胞数目+甘油三酯+LDL+白蛋白
  +times+age+mobilizer_bw,
  data = normalization_data,
  method = "svmRadial",
  trControl = train_control,
  tuneGrid = tuneGrid,  
  metric = "ROC",  
)
print(model5)
print(model5$bestTune)
best_predictions <- subset(model5$pred, sigma == model5$bestTune$sigma)
roc_curve <- roc(best_predictions$obs, best_predictions$No)
plot(roc_curve, main = "ROC Curve for Optimal Model", col = "blue", print.auc = TRUE)
lines(roc_curve, col="yellow", lty=1)
fold_accuracies <- numeric(10)
for (fold in unique(best_predictions$Resample)) {
  fold_data <- subset(best_predictions, Resample == fold)
  predicted_classes <- ifelse(fold_data$pos > 0.5, "pos", "neg")
  predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
  accuracy <- sum(predicted_classes == fold_data$obs) / nrow(fold_data)
  fold_accuracies[as.numeric(gsub("Fold", "", fold))] <- accuracy
  cat("Fold", fold, "Accuracy:", accuracy, "\n")
}
mean_accuracy <- mean(fold_accuracies)



#### K Nearest Neighbours####
library(caret)
library(pROC)
result2=result[,c(4,12,13,14,15,17,18,19,21,23,24,25,30,31,33,34,35,53,55,56,54,57,59,38)]
result1=result[,c(4,12,13,14,15,17,18,19,21,23,24,25,30,31,33,34,35,53,55,56,54,57,59)]
for (i in 1:23){
  for (j in 1:896){
    result2[j,i]=(result1[j,i]-min(result1[,i])) / (max(result1[,i])-min(result1[,i]))
    
  }
}
result2$D4_CD34_binary=as.numeric(result2$D4.CD34>500)
result2$D4_CD34_binary <- as.factor(ifelse(result2$D4_CD34_binary == 1, "pos", "neg"))
levels(result_factor$D4_CD34_binary) <- c("neg", "pos")
ctrl <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,          
  summaryFunction = twoClassSummary,  
  savePredictions = "final")
tune_grid <- expand.grid(k = seq(3, 15, by = 2))  
set.seed(772)
model6 <- train(
  D4_CD34_binary ~ 性别.男1.女2.+尿酸 + 基线白细胞.X109.l. + sum_mobilizer + 血小板  
  + 血红蛋白.g.l. + 体重.Kg. + 升高.米. + 中性粒细胞数 + 单核细胞数 + 红细胞.x10.12.l. +  
    肌酐 + MCHC + HCT + 淋巴细胞数目 + 甘油三酯 + LDL + 白蛋白 +  
    times + age + mobilizer_bw,   
  data = result2,
  method = "knn",
  trControl = ctrl,
  metric = "ROC",        
  tuneGrid = tune_grid,  
  preProcess = c("center", "scale")  
)
print(model6)
plot(model6)            
best_predictions <- subset(model6$pred, k == model6$bestTune$k)
roc_curve <- roc(best_predictions$obs, best_predictions$pos)
plot(roc_curve, main = "ROC Curve for Optimal Model", col = "blue", print.auc = TRUE)
lines(roc_curve, col="purple", lty=2)
fold_accuracies <- numeric(10)
for (fold in unique(best_predictions$Resample)) {
  fold_data <- subset(best_predictions, Resample == fold)
  predicted_classes <- ifelse(fold_data$pos > 0.5, "pos", "neg")
  predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
  accuracy <- sum(predicted_classes == fold_data$obs) / nrow(fold_data)
  fold_accuracies[as.numeric(gsub("Fold", "", fold))] <- accuracy
  cat("Fold", fold, "Accuracy:", accuracy, "\n")
}
mean_accuracy <- mean(fold_accuracies)





#### AdaBoost####
library(caret)
library(ada)
ctrl <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,          
  summaryFunction = twoClassSummary, 
  savePredictions = "final")
set.seed(9)
model7 <- train(
  D4_CD34_binary ~ 尿酸 + 基线白细胞.X109.l. + sum_mobilizer + 血小板 + 血红蛋白.g.l. + 体重.Kg. + 升高.米. + 中性粒细胞数 + 单核细胞数 + 红细胞.x10.12.l. + 肌酐 + MCHC + HCT + 淋巴细胞数目 + 甘油三酯 + LDL + 白蛋白 + times + age + mobilizer_bw,
  data = result2,
  method = "ada",            
  trControl = ctrl,
  metric = "ROC",            
  tuneLength = 5             
)
print(model7)
plot(model7) 
best_predictions <- subset(model7$pred, maxdepth== model7$bestTune$maxdepth)
roc_curve <- roc(best_predictions$obs, best_predictions$pos)
plot(roc_curve, main = "ROC Curve for Optimal Model", col = "blue", print.auc = TRUE)
lines(roc_curve, col="gray", lty=1)
fold_accuracies <- numeric(10)
for (fold in unique(best_predictions$Resample)) {
  fold_data <- subset(best_predictions, Resample == fold)
  predicted_classes <- ifelse(fold_data$pos > 0.5, "pos", "neg")
  predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
  accuracy <- sum(predicted_classes == fold_data$obs) / nrow(fold_data)
  fold_accuracies[as.numeric(gsub("Fold", "", fold))] <- accuracy
  cat("Fold", fold, "Accuracy:", accuracy, "\n")
}
mean_accuracy <- mean(fold_accuracies)
predicted_classes <- ifelse(best_predictions$pos > 0.5, "pos", "neg")
predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
confusion_matrix <- confusionMatrix(predicted_classes, best_predictions$obs)
print(confusion_matrix)




##### Neural Networks####
library(caret)
library(nnet)
ctrl <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,        
  summaryFunction = twoClassSummary, 
  savePredictions = "final")
tune_grid <- expand.grid(
  size = c(3, 5, 7),     
  decay = c(0, 0.1, 0.5) 
)
set.seed(123)
model8 <- train(
  D4_CD34_binary~  尿酸+基线白细胞.X109.l.+sum_mobilizer+血小板
  +血红蛋白.g.l.+体重.Kg.+升高.米.+中性粒细胞数+单核细胞数+红细胞.x10.12.l.
  +肌酐+MCHC+HCT+淋巴细胞数目+甘油三酯+LDL+白蛋白
  +times+age+mobilizer_bw,
  data = result2,
  method = "nnet",
  trControl = ctrl,
  metric = "ROC",        
  tuneGrid = tune_grid,  
  preProcess = c("center", "scale"), 
  trace = FALSE         
)
print(model8)
plot(model8)              
best_predictions <- subset(model8$pred, size== model8$bestTune$size)
roc_curve <- roc(best_predictions$obs, best_predictions$pos)
lines(roc_curve, col="orange", lty=1)
plot(roc_curve, main = "ROC Curve for Optimal Model", col = "blue", print.auc = TRUE)
fold_accuracies <- numeric(10)
for (fold in unique(best_predictions$Resample)) {
  fold_data <- subset(best_predictions, Resample == fold)
  predicted_classes <- ifelse(fold_data$pos > 0.5, "pos", "neg")
  predicted_classes <- factor(predicted_classes, levels = c("neg", "pos"))
  accuracy <- sum(predicted_classes == fold_data$obs) / nrow(fold_data)
  fold_accuracies[as.numeric(gsub("Fold", "", fold))] <- accuracy
  cat("Fold", fold, "Accuracy:", accuracy, "\n")
}
mean_accuracy <- mean(fold_accuracies)
legend("bottomright", legend=c("Linear regression", "Decision tree","Random forest","SVM","KNN","AdaBoost","NN"), col=c("blue", "red","green","yellow","purple","gray","orange"), lty=c(1,1,2,1,2,1,1),cex = 0.75,bty="n",xjust=1,yjust=0)

